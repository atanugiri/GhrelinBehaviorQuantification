{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Add project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Add the parent of the *outer* DLC-Jupyter-Notebooks folder to sys.path\n",
    "project_root = Path().resolve().parents[0]  # This is /Users/atanugiri/Downloads/GhrelinBehaviorQuantification\n",
    "print(project_root)\n",
    "sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Connect to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB with a CSV fallback\n",
    "from Python_scripts import config\n",
    "import pandas as pd\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# Try to connect to PostgreSQL using centralized config; fall back to CSV files in DATA_DIR.\n",
    "try:\n",
    "    conn = config.get_conn()\n",
    "    cursor = conn.cursor()\n",
    "    use_csv_fallback = False\n",
    "    print(\"[INFO] Connected to Postgres\")\n",
    "except Exception as exc:\n",
    "    print(\"[WARN] DB connection failed, falling back to CSVs:\", exc)\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    use_csv_fallback = True\n",
    "    data_dir = config.get_data_dir()\n",
    "    print(f\"[INFO] Using DATA_DIR = {data_dir}\")\n",
    "\n",
    "    # Load available dlc_table_*.csv files into a dict for later fallback lookups\n",
    "    dlc_tables = {}\n",
    "    if data_dir.exists():\n",
    "        for p in data_dir.glob('dlc_table_*.csv'):\n",
    "            try:\n",
    "                dlc_tables[p.name] = pd.read_csv(p)\n",
    "                print(f\"[INFO] Loaded {p.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Couldn't load {p}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARN] DATA_DIR does not exist: {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path resolver helper: maps stored metadata paths to local files under DATA_DIR\n",
    "from pathlib import Path\n",
    "# Ensure data_dir is available whether or not we used the CSV fallback earlier\n",
    "try:\n",
    "    data_dir\n",
    "except NameError:\n",
    "    data_dir = config.get_data_dir()\n",
    "\n",
    "def resolve_video_path(stored_path, data_dir=data_dir):\n",
    "    \"\"\"Resolve a video or CSV path recorded in the metadata table to a local file under DATA_DIR.\n",
    "\n",
    "    Behavior:\n",
    "    - If stored_path is an absolute or relative path that exists locally, return Path(stored_path).\n",
    "    - If stored_path is a basename or relative path, try locating it under DATA_DIR (recursive rglob).\n",
    "    - If not found, return Path(stored_path) (caller can decide how to handle missing files).\n",
    "    \"\"\"\n",
    "    if stored_path is None:\n",
    "        return None\n",
    "    p = Path(stored_path)\n",
    "    # If path exists as provided, return it\n",
    "    if p.exists():\n",
    "        return p\n",
    "    # If data_dir is usable, search for the filename within it\n",
    "    if data_dir is not None and data_dir.exists():\n",
    "        matches = list(data_dir.rglob(p.name))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        # try joining directly\n",
    "        cand = data_dir / p\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    # fallback to original Path (may be non-existent)\n",
    "    return p\n",
    "\n",
    "# Quick smoke-check (prints only when run interactively)\n",
    "if 'dlc_tables' in globals():\n",
    "    print(f\"[INFO] dlc_tables has {len(dlc_tables)} entries; DATA_DIR={data_dir}\")\n",
    "else:\n",
    "    print(f\"[INFO] DATA_DIR={data_dir}; no dlc_tables loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Python_scripts.Data_analysis.fetch_id_list as fetch_mod\n",
    "importlib.reload(fetch_mod)\n",
    "from Python_scripts.Data_analysis.fetch_id_list import fetch_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Python_scripts.Feature_functions.angle_features\n",
    "import Python_scripts.Data_analysis.plot_groupwise_bar\n",
    "\n",
    "importlib.reload(Python_scripts.Feature_functions.angle_features)\n",
    "importlib.reload(Python_scripts.Data_analysis.plot_groupwise_bar)\n",
    "\n",
    "from Python_scripts.Feature_functions.angle_features import (\n",
    "    angle_features_for_trial, batch_angle_features\n",
    ")\n",
    "from Python_scripts.Data_analysis.plot_groupwise_bar import plot_groupwise_bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Fetch id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"AllTask\"\n",
    "bad_id = [549, 559, 566, 567, 570, 571, 595, 617, 621, 638, 640, 36]\n",
    "\n",
    "saline_id, ghrelin_id, exc_id, inh_id = fetch_id_list(\n",
    "    conn,\n",
    "    task_name=None, #['FoodLight', 'ToyOnly', 'ToyLight', 'LightOnly'],\n",
    "    dose_mult=2,\n",
    "    genotype=\"white\",\n",
    "    bad_ids=bad_id,\n",
    "    csv_prefix=\"dlc_table\",   # -> dlc_table_saline.csv, dlc_table_ghrelin.csv, ...\n",
    "    min_trial_length=None     # or 600\n",
    ")\n",
    "\n",
    "print(f\"saline_id: {saline_id}\\n\")\n",
    "print(f\"ghrelin_id: {ghrelin_id}\\n\")\n",
    "print(f\"exc_id: {exc_id}\\n\")\n",
    "print(f\"inh_id: {inh_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Calculate angle features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Batch call with different input parameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --- Configure once ---å\n",
    "likelihood_thr=np.arange(0.65, 0.68, 0.025)\n",
    "window_size=None\n",
    "\n",
    "# Put every group you *might* use here; leave others as None or [] when not needed.\n",
    "group_specs = {\n",
    "    \"Saline\":  saline_id,\n",
    "    # \"Ghrelin\": ghrelin_id,\n",
    "    \"Inhibitory\": inh_id,\n",
    "    \"Excitatory\": exc_id,\n",
    "}\n",
    "# Keep only defined & non-empty groups\n",
    "group_specs = {label: ids for label, ids in group_specs.items() if ids not in (None, [], ())}\n",
    "\n",
    "outfile = f\"White_Modulation_2X_{task_name}_ang_likelihood_sweep.pdf\"\n",
    "with PdfPages(outfile) as pdf:\n",
    "    for likelihood in likelihood_thr:\n",
    "        print(f\"[INFO] Analyzing likelihood = {likelihood}\")\n",
    "\n",
    "        # Compute all groups for this window size\n",
    "        frames = []\n",
    "        for label, ids in group_specs.items():\n",
    "            df = batch_angle_features(\n",
    "                conn, ids, likelihood_threshold=likelihood, smooth_window=window_size,\n",
    "            )\n",
    "            # Keep what we need; add group label\n",
    "            df = df[['trial_id', 'head_body_misalignment_p95']].copy().dropna()\n",
    "            df['group'] = label\n",
    "            frames.append(df)\n",
    "\n",
    "        if not frames:\n",
    "            print(\"[WARN] No groups provided—skipping this window.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        # Plot\n",
    "        order = list(group_specs.keys())\n",
    "        fig, ax = plot_groupwise_bar(\n",
    "            df,\n",
    "            y='head_body_misalignment_p95',\n",
    "            ylabel='head_body_misalignment_p95',\n",
    "            plot_type='bar',\n",
    "            show_points=False,\n",
    "            order=order,\n",
    "            show_stats=True,\n",
    "            tests_to_show=(\"ranksums\", \"ttest\", \"anova\")  # if supported\n",
    "        )\n",
    "        ax.set_title(f\"{task_name} | likelihood={likelihood}\", pad=20)\n",
    "\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[✓] Saved {outfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Single call with fixed hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smooth_window=None\n",
    "likelihood_threshold=0.65\n",
    "\n",
    "# Put every group you *might* use here; leave others as None or [] when not needed.\n",
    "group_specs = {\n",
    "    \"Saline\":  saline_id,\n",
    "    \"Ghrelin\": ghrelin_id,\n",
    "    # \"Inhibitory\": inh_id,\n",
    "    # \"Excitatory\": exc_id,\n",
    "}\n",
    "# Keep only defined & non-empty groups\n",
    "group_specs = {label: ids for label, ids in group_specs.items() if ids not in (None, [], ())}\n",
    "\n",
    "frames = []\n",
    "for label, ids in group_specs.items():\n",
    "    df = batch_angle_features(\n",
    "        conn, ids, likelihood_threshold=likelihood_threshold, smooth_window=smooth_window\n",
    "    )\n",
    "    # Keep what we need; add group label\n",
    "    df = df[['trial_id', 'head_body_misalignment_p95']].copy().dropna()\n",
    "    df['group'] = label\n",
    "    frames.append(df)\n",
    "\n",
    "if not frames:\n",
    "    print(\"[WARN] No groups provided—skipping this window.\")\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Plot\n",
    "order = list(group_specs.keys())\n",
    "\n",
    "ax = plot_groupwise_bar(\n",
    "    df, y='head_body_misalignment_p95',\n",
    "    ylabel='Mean head_body_misalignment_p95',\n",
    "    plot_type='bar', show_points=True,\n",
    "    order=order, show_stats=True,\n",
    "    tests_to_show=(\"ranksums\",\"ttest\")  # optional\n",
    ")\n",
    "fig = ax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[1].set_title(f\"{task_name} | likelihood_threshold={likelihood_threshold}\", pad=20)\n",
    "# ax[1].set_ylim([0, 1.75])\n",
    "fig.savefig(f\"White_2X_{task_name}_ang.pdf\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Save Excel file for data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Get the unique trial IDs from df\n",
    "trial_ids = df['trial_id'].unique().tolist()\n",
    "\n",
    "# Step 2. Query the database for task & modulation — or build meta_df from CSV fallback\n",
    "if conn is not None:\n",
    "    query = \"\"\"\n",
    "    SELECT id, task, modulation, video_path\n",
    "    FROM dlc_table\n",
    "    WHERE id = ANY(%s);\n",
    "    \"\"\"\n",
    "    meta_df = pd.read_sql_query(query, conn, params=(trial_ids,))\n",
    "else:\n",
    "    # Build meta_df by concatenating available dlc_table CSVs and filtering by id\n",
    "    csv_frames = []\n",
    "    for name, table_df in (dlc_tables.items() if 'dlc_tables' in globals() else []):\n",
    "        if isinstance(table_df, pd.DataFrame):\n",
    "            csv_frames.append(table_df)\n",
    "    if csv_frames:\n",
    "        meta_all = pd.concat(csv_frames, ignore_index=True)\n",
    "        meta_df = meta_all[meta_all['id'].isin(trial_ids)][['id', 'task', 'modulation']].drop_duplicates()\n",
    "    else:\n",
    "        # No metadata available; create an empty dataframe with expected columns\n",
    "        meta_df = pd.DataFrame(columns=['id', 'task', 'modulation'])\n",
    "\n",
    "# Step 3. Merge with df on id\n",
    "# If meta_df has an 'id' column matching trial_id, merge; otherwise, attempt to use a 'trial_id' column\n",
    "if 'id' in meta_df.columns:\n",
    "    df_out = df.merge(meta_df, left_on='trial_id', right_on='id', how='left')\n",
    "    df_out = df_out.drop(columns=['id']) if 'id' in df_out.columns else df_out\n",
    "else:\n",
    "    df_out = df.copy()\n",
    "\n",
    "# Optional: attempt to resolve video paths if present in meta_df (adds a column 'resolved_video_path')\n",
    "if 'video_path' in meta_df.columns:\n",
    "    df_out['resolved_video_path'] = df_out['trial_id'].map(lambda tid: resolve_video_path(meta_df.loc[meta_df['id']==tid, 'video_path'].iloc[0] if not meta_df.loc[meta_df['id']==tid, 'video_path'].empty else None))\n",
    "\n",
    "# Step 4. Save to Excel\n",
    "out_path = Path.cwd() / \"10X_White_Angle.xlsx\"\n",
    "df_out.to_excel(out_path, index=False)\n",
    "print(f\"[✓] Saved {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gastric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
