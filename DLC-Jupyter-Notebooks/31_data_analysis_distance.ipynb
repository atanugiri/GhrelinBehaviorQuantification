{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Add project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Add the parent of the *outer* DLC-Jupyter-Notebooks folder to sys.path\n",
    "project_root = Path().resolve().parents[0]  # This is /Users/atanugiri/Downloads/GhrelinBehaviorQuantification\n",
    "print(project_root)\n",
    "sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Connect to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB with a CSV fallback\n",
    "from Python_scripts import config\n",
    "import pandas as pd\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# Try to connect to PostgreSQL using centralized config; fall back to CSV files in DATA_DIR.\n",
    "try:\n",
    "    conn = config.get_conn()\n",
    "    cursor = conn.cursor()\n",
    "    use_csv_fallback = False\n",
    "    print(\"[INFO] Connected to Postgres\")\n",
    "except Exception as exc:\n",
    "    print(\"[WARN] DB connection failed, falling back to CSVs:\", exc)\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    use_csv_fallback = True\n",
    "    data_dir = config.get_data_dir()\n",
    "    print(f\"[INFO] Using DATA_DIR = {data_dir}\")\n",
    "\n",
    "    # Load available dlc_table_*.csv files into a dict for later fallback lookups\n",
    "    dlc_tables = {}\n",
    "    if data_dir.exists():\n",
    "        for p in data_dir.glob('dlc_table_*.csv'):\n",
    "            try:\n",
    "                dlc_tables[p.name] = pd.read_csv(p)\n",
    "                print(f\"[INFO] Loaded {p.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Couldn't load {p}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARN] DATA_DIR does not exist: {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Python_scripts.Data_analysis.fetch_id_list as fetch_mod\n",
    "importlib.reload(fetch_mod)\n",
    "from Python_scripts.Data_analysis.fetch_id_list import fetch_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Python_scripts.Feature_functions.motion_features_per_minute\n",
    "import Python_scripts.Data_analysis.plot_groupwise_bar\n",
    "\n",
    "importlib.reload(Python_scripts.Feature_functions.motion_features_per_minute)\n",
    "importlib.reload(Python_scripts.Data_analysis.plot_groupwise_bar)\n",
    "\n",
    "from Python_scripts.Feature_functions.motion_features_per_minute import (\n",
    "    compute_motion_features_per_minute, batch_compute_motion_features_per_minute\n",
    ")\n",
    "from Python_scripts.Data_analysis.plot_groupwise_bar import plot_groupwise_bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Fetch id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"AllTask\"\n",
    "bad_id = [549, 559, 566, 567, 570, 571, 595, 617, 621, 638, 640, 36]\n",
    "\n",
    "saline_id, ghrelin_id, exc_id, inh_id = fetch_id_list(\n",
    "    conn,\n",
    "    task_name=None, #['FoodLight', 'ToyOnly', 'ToyLight', 'LightOnly'],\n",
    "    dose_mult=10,\n",
    "    genotype=\"white\",\n",
    "    bad_ids=bad_id,\n",
    "    csv_prefix=\"dlc_table\",   # -> dlc_table_saline.csv, dlc_table_ghrelin.csv, ...\n",
    "    min_trial_length=None     # or 600\n",
    ")\n",
    "\n",
    "print(f\"saline_id: {saline_id}\\n\")\n",
    "print(f\"ghrelin_id: {ghrelin_id}\\n\")\n",
    "print(f\"exc_id: {exc_id}\\n\")\n",
    "print(f\"inh_id: {inh_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Calculate velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Batch call with different input parameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --- Configure once ---\n",
    "bodypart = 'Head'          # or 'Midback'\n",
    "time_limit = None          # e.g., 120 for first 2 minutes; None for full trial\n",
    "smooth = True              # IMPORTANT: set True, otherwise 'window' has no effect\n",
    "window_range = range(5, 26, 5)  # 11,15,19,23,27\n",
    "\n",
    "# Put every group you *might* use here; leave others as None or [] when not needed.\n",
    "group_specs = {\n",
    "    \"Saline\":  saline_id,\n",
    "    # \"Ghrelin\": ghrelin_id,\n",
    "    \"Inhibitory\": inh_id,\n",
    "    \"Excitatory\": exc_id,\n",
    "}\n",
    "# Keep only defined & non-empty groups\n",
    "group_specs = {label: ids for label, ids in group_specs.items() if ids not in (None, [], ())}\n",
    "\n",
    "outfile = f\"White_2X_{task_name}_{bodypart}_velocity_window_sweep.pdf\"\n",
    "with PdfPages(outfile) as pdf:\n",
    "    for window_size in window_range:\n",
    "        print(f\"[INFO] Analyzing window_size = {window_size}\")\n",
    "\n",
    "        # Compute all groups for this window size\n",
    "        frames = []\n",
    "        for label, ids in group_specs.items():\n",
    "            df = batch_compute_motion_features_per_minute(\n",
    "                conn, ids,\n",
    "                bodypart=bodypart,\n",
    "                time_limit=time_limit,\n",
    "                smooth=smooth,\n",
    "                window=window_size,\n",
    "                # min_duration_s=5.0,  # keep default unless you want to drop very short trials\n",
    "            )\n",
    "            # Keep what we need; add group label\n",
    "            df = df[['trial_id', 'velocity_per_min']].copy().dropna()\n",
    "            df['group'] = label\n",
    "            frames.append(df)\n",
    "\n",
    "        if not frames:\n",
    "            print(\"[WARN] No groups provided—skipping this window.\")\n",
    "            continue\n",
    "\n",
    "        df_vel = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        # Plot (your existing plotter)\n",
    "        order = list(group_specs.keys())\n",
    "        fig, ax = plot_groupwise_bar(\n",
    "            df_vel,\n",
    "            y='velocity_per_min',\n",
    "            ylabel='Average speed (units/min)',\n",
    "            plot_type='bar',\n",
    "            show_points=False,\n",
    "            order=order,\n",
    "            show_stats=True,\n",
    "            tests_to_show=(\"ranksums\", \"ttest\", \"anova\")  # if supported\n",
    "        )\n",
    "        ax.set_title(f\"{task_name} | {bodypart} | window={window_size}\", pad=20)\n",
    "\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"[✓] Saved {outfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Single call with fixed hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configure once ---\n",
    "bodypart = 'Head'\n",
    "time_limit = None\n",
    "smooth = False\n",
    "window = 5  # smoothing window for compute_motion_features (if smooth=True)\n",
    "\n",
    "# Put every group we *might* use here; leave others as None or [] when not needed.\n",
    "group_specs = {\n",
    "    \"Saline\":  saline_id,    # lists/arrays of trial IDs, defined earlier\n",
    "    \"Ghrelin\": ghrelin_id,\n",
    "    # \"Inhibitory\": inh_id,\n",
    "    # \"Excitatory\": exc_id,\n",
    "}\n",
    "\n",
    "# Keep only defined & non-empty groups\n",
    "group_specs = {label: ids for label, ids in group_specs.items() if ids not in (None, [], ())}\n",
    "\n",
    "# Compute all groups\n",
    "frames = []\n",
    "for label, ids in group_specs.items():\n",
    "    df = batch_compute_motion_features_per_minute(\n",
    "        conn, ids,\n",
    "        bodypart=bodypart,\n",
    "        time_limit=time_limit,\n",
    "        smooth=smooth,\n",
    "        window=window,\n",
    "        # min_duration_s=5.0,\n",
    "    )\n",
    "    # Keep just what we need for plotting; add group label\n",
    "    df = df[['trial_id', 'velocity_per_min']].copy()\n",
    "    df['group'] = label\n",
    "    frames.append(df)\n",
    "\n",
    "if not frames:\n",
    "    raise ValueError(\"[WARN] No groups provided—nothing to plot.\")\n",
    "\n",
    "df_vel = pd.concat(frames, ignore_index=True)\n",
    "df_vel = df_vel.dropna(subset=['velocity_per_min'])\n",
    "\n",
    "# Plot\n",
    "order = list(group_specs.keys())  # consistent ordering across pages\n",
    "ax = plot_groupwise_bar(\n",
    "    df_vel, y='velocity_per_min',\n",
    "    ylabel='Average speed (units/min)',\n",
    "    plot_type='bar', show_points=False,\n",
    "    order=order, show_stats=True,\n",
    "    tests_to_show=(\"ranksums\",\"ttest\")  # optional\n",
    ")\n",
    "fig = ax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[1].set_title(f\"{task_name} | {bodypart} | window={window}\", pad=20)\n",
    "# ax[1].set_ylim([0, 12])\n",
    "fig.savefig(f\"White_10X_{task_name}_velocity.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Save Excel file for data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Get the unique trial IDs from df_vel\n",
    "trial_ids = df_vel['trial_id'].unique().tolist()\n",
    "\n",
    "# Step 2. Query the database for task & modulation\n",
    "query = \"\"\"\n",
    "SELECT id, task, modulation\n",
    "FROM dlc_table\n",
    "WHERE id = ANY(%s);\n",
    "\"\"\"\n",
    "meta_df = pd.read_sql_query(query, conn, params=(trial_ids,))\n",
    "\n",
    "# Step 3. Merge with df_vel on id\n",
    "df_out = df_vel.merge(meta_df, left_on='trial_id', right_on='id', how='left')\n",
    "\n",
    "# Optional: drop redundant id column if you just want trial_id\n",
    "df_out = df_out.drop(columns=['id'])\n",
    "\n",
    "# Step 4. Save to Excel\n",
    "df_out.to_excel(\"10X_White_Velocity.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gastric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
