{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries needed for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Kernel before running this cell if you've run other matplotlib commands\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import deeplabcut\n",
    "    import tkinter\n",
    "    from tkinter import filedialog\n",
    "    \n",
    "    print(f'Using DeepLabCut version: {deeplabcut. __version__}')\n",
    "\n",
    "except:\n",
    "    print(\"Please run the notebook in in your local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You might have to import torch to use PyTorch engine ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "    print(\"cuDNN Enabled:\", torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check PyTorch in DeepLabCut ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"DeepLabCut is using PyTorch with GPU support.\")\n",
    "else:\n",
    "    print(\"DeepLabCut is using PyTorch on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by selecting the list of videos to be included in the model. You could manually type the full path of each video in a python list as argument of the deeplabcut.create_new_project() function, like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Windows users need to use the double backslash for path directories or a python raw filestring.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we use ```tkinter``` to open a file dialoge and save the file paths in a python list called ```videolist```: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = filedialog.askopenfilenames(title='Choose new video files to analyze in DeepLabCut:')\n",
    "videolist = list(video_files)\n",
    "\n",
    "print(f'{len(videolist)} videos selected:')\n",
    "for i in range(len(videolist)): \n",
    "    print(videolist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new project using the video paths in ```videolist```, give the project a name and set a few parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new DLC Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = deeplabcut.create_new_project(\n",
    "    'DLC-WhiteAnimals', 'Atanu', \n",
    "    [r'C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Dallas.mp4'], \n",
    "    working_directory='C:/DeepLabCutProjects/', copy_videos=False, multianimal=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "You can load existing DeepLabCut projects by specifying the config_path as below:\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_videos = [r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Austin.mp4\",\n",
    "              r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Berlin.mp4\",\n",
    "              r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Houston.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Toronto.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_London.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Paris.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Phoenix.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Doc.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Dopey.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Grumpy.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Sneezy.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Bashful.mp4\",\n",
    "             r\"C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Happy.mp4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.add_new_videos(config_path, new_videos, copy_videos=False, extract_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Backend (TensorFlow or PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(\"Using TensorFlow backend.\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"Using PyTorch backend.\")\n",
    "    except ImportError:\n",
    "        print(\"No supported backend found. Ensure TensorFlow or PyTorch is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a new project has been created with a specific directory structure and configuration file, we need to tweak some parameters to tailor the bodyparts we want to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r'C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\\config.yaml'\n",
    "print(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(config_path)\n",
    "print('Please edit bodyparts list to be tracked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as file:\n",
    "    config_content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once happy with all ```bodyparts```, ```skeleton:``` and ```numframes2pick:``` settings, start extracting frames to label:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Frames to Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames(\n",
    "    config_path, mode='automatic', \n",
    "    algo='uniform', \n",
    "    crop='GUI', # <--- THIS IS KEY: Tells DLC you want to crop\n",
    "    userfeedback=True # <--- THIS IS KEY: Ensures an interactive GUI for selection\n",
    ")\n",
    "\n",
    "# deeplabcut.extract_frames(config_path, \"manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Frames (Do it in GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot your labeled frames to check your annotation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(\n",
    "    config_path,\n",
    "    shuffle=3,\n",
    "    trainingsetindex=0,\n",
    "    device=\"cuda:0\",\n",
    "    max_snapshots_to_keep=5,\n",
    "    displayiters=100,\n",
    "    save_epochs=5,\n",
    "    epochs=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(config_path, Shuffles=[3], plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze new Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "videolist = [r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4\",\n",
    "            r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4\",\n",
    "            r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4\"]\n",
    "# destfolder = r\"C:\\DeepLabCutProjects\\data\\FoodLight\\DlcDataPytorch\"\n",
    "\n",
    "deeplabcut.analyze_videos(config_path, videos=videolist, shuffle=3, gputouse=\"cuda:0\", save_as_csv=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All videos in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# base data path\n",
    "base_path = r\"C:\\DeepLabCutProjects\\data\"\n",
    "\n",
    "# List of subfolders to process\n",
    "conditions = ['ToyOnlyWhite', 'ToyLightWhite']\n",
    "\n",
    "# Loop over all conditions\n",
    "for condition in conditions:\n",
    "    print(f\"\\nProcessing: {condition}\")\n",
    "\n",
    "    video_dir = os.path.join(base_path, condition, \"SplitVideos\")\n",
    "    destfolder = os.path.join(base_path, condition, \"DlcDataPytorch\")\n",
    "    os.makedirs(destfolder, exist_ok=True)\n",
    "\n",
    "    # Get list of video files\n",
    "    videolist = [\n",
    "        os.path.join(video_dir, f)\n",
    "        for f in os.listdir(video_dir)\n",
    "        if f.endswith(('.mp4', '.avi'))\n",
    "    ]\n",
    "\n",
    "    # Skip if no videos\n",
    "    if not videolist:\n",
    "        print(f\"No videos found in {video_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Analyze\n",
    "    print(f\"Analyzing {len(videolist)} videos, saving to {destfolder}\")\n",
    "    deeplabcut.analyze_videos(\n",
    "        config_path,\n",
    "        videos=videolist,\n",
    "        shuffle=3,\n",
    "        gputouse=\"cuda:0\",\n",
    "        save_as_csv=True,\n",
    "        destfolder=destfolder\n",
    "    )\n",
    "\n",
    "print(\"\\nAll batches submitted for analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Pose Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.filterpredictions(config_path, videolist, shuffle=3, filtertype='median', p_bound=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All videos in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# base data path\n",
    "base_path = r\"C:\\DeepLabCutProjects\\data\"\n",
    "\n",
    "# List of subfolders to process\n",
    "conditions = ['ToyOnlyWhite']\n",
    "\n",
    "# Loop over all conditions\n",
    "for condition in conditions:\n",
    "    print(f\"\\nProcessing: {condition}\")\n",
    "\n",
    "    video_dir = os.path.join(base_path, condition, \"SplitVideos\")\n",
    "\n",
    "    # Get list of video files\n",
    "    videolist = [\n",
    "        os.path.join(video_dir, f)\n",
    "        for f in os.listdir(video_dir)\n",
    "        if f.endswith(('.mp4', '.avi'))\n",
    "    ]\n",
    "\n",
    "    # Skip if no videos\n",
    "    if not videolist:\n",
    "        print(f\"No videos found in {video_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Analyze\n",
    "    deeplabcut.filterpredictions(\n",
    "        config_path,\n",
    "        videolist,\n",
    "        shuffle=3,\n",
    "        save_as_csv=True\n",
    "    )\n",
    "\n",
    "print(\"\\nAll batches submitted for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyzeskeleton(config_path, videolist, videotype='.mp4', shuffle=1, trainingsetindex=0, save_as_csv=False, destfolder=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labeled videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# video_dir = r\"C:\\DeepLabCutProjects\\data\\FoodOnly\\SplitVideos\"\n",
    "# videolist = [os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi'))]\n",
    "\n",
    "# videolist = [r\"C:\\DeepLabCutProjects\\DLC-Atanu-2025-06-10\\videos\\FoodOnly\\FoodOnly_8_28_24_S3P_Cyan_Trial1.mp4\"]\n",
    "\n",
    "# deeplabcut.create_labeled_video(config_path, videolist, draw_skeleton=False, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(\n",
    "    config_path,\n",
    "    videolist,\n",
    "    shuffle=3,\n",
    "    filtered=True,\n",
    "    fastmode=False,\n",
    "    save_frames=False,\n",
    "    displayedbodyparts=['Head', 'Neck', 'Midback', 'Lowerback', 'Tailbase']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(config_path, videolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Active Learning -> Network Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load new videos to analyze and/or merge to the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract outlier frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is the interesting part. Instead of including more videos to the project directly, and extracting frames as usual with kmeans, we are taking advantage of the previous model to tell us what frames exactly to label. This active learning step helps us recognize the shortcomings of our model and correct it in a targeted manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config_path, videolist, outlieralgorithm='uncertain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine Labels: Augmentation of the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted new frames, we need to go back and start labeling. Instead of starting from the beginning, though, we are provided the model predictions and have to drag and drop them in place. **Note:** Make sure to remove labels that are not visible, the model will often guess the expected position based on learned geometric constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can again plot your labeled frames to check annotation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you could get an error message like [this](https://github.com/DeepLabCut/DeepLabCut/issues/232) telling you that saving the video path failed. In this case, you need to add the new video paths manually for DLC to include these in the new training set. You can either add them by hand, writing in the config.yaml file in the same format as the first video paths (see [here](https://github.com/DeepLabCut/DeepLabCut/issues/663#issuecomment-619274975)), or you can run the following command to add the list of videos to your config file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the permission error persists, try starting a new anaconda terminal as administrator (right click > run as administrator) and then starting jupyter notebook with elevated privileges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After refining all outlier frames extracted above, merge the datasets to combine old and new labels in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Make sure that the new videos have been included in the config.yaml file without permission issues (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a new model with an expanded dataset, you could either choose to start fresh with new data, or use the previous model as pre-trained network for your next model. Although not yet extensively verified, lets belief that transfer learning at least won't harm the new model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of own pre-trained model\n",
    "init_weights: D:\\FacialExpression\\old-DLC-Project\\dlc-models\\iteration-0\\DLCApr14-trainset95shuffle1\\train\\snapshot-1030000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start over again..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cf59f4f35cbd5b03b7320385623601e0d1d6065449752291df1bcf50543fed6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
